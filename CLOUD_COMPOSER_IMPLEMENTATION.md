# Cloud Composer Automation - ImplementaciÃ³n Completa

## ğŸ“‹ Resumen

Se ha implementado un sistema completo de automatizaciÃ³n usando Cloud Composer (Apache Airflow) con 3 DAGs principales para ETL/ML, mantenimiento preventivo y generaciÃ³n de reportes.

## ğŸ¯ DAGs Implementados

### 1. ETL and ML Training DAG (`etl_ml_training`)

**PropÃ³sito:** Extrae datos de Cloud SQL, procesa caracterÃ­sticas con PySpark en Dataproc, y entrena el modelo ML.

**Schedule:** Semanal (Domingos a las 2 AM)

**Tareas:**
1. **extract_assets_data** - Extrae datos de activos de Cloud SQL a GCS
2. **extract_work_orders_data** - Extrae datos de Ã³rdenes de trabajo a GCS
3. **create_dataproc_cluster** - Crea cluster de Dataproc
4. **feature_engineering** - Ejecuta PySpark job para ingenierÃ­a de caracterÃ­sticas
5. **train_model** - Entrena modelo ML vÃ­a Backend API
6. **deploy_model** - Despliega modelo a Vertex AI
7. **delete_dataproc_cluster** - Elimina cluster (siempre se ejecuta)
8. **notify_success** - EnvÃ­a email de Ã©xito

**CaracterÃ­sticas:**
- âœ… ExtracciÃ³n paralela de datos
- âœ… Procesamiento distribuido con PySpark
- âœ… IntegraciÃ³n con Backend API
- âœ… Despliegue automÃ¡tico a Vertex AI
- âœ… Limpieza automÃ¡tica de recursos
- âœ… Notificaciones por email

**ConfiguraciÃ³n:**
```python
PROJECT_ID = Variable.get("gcp_project_id")
REGION = Variable.get("gcp_region")
BUCKET_NAME = Variable.get("gcs_bucket_name")
```

### 2. Preventive Maintenance DAG (`preventive_maintenance_generator`)

**PropÃ³sito:** Genera Ã³rdenes de trabajo para planes de mantenimiento vencidos.

**Schedule:** Diario (6 AM)

**Tareas:**
1. **query_due_maintenance_plans** - Consulta planes vencidos en la BD
2. **create_work_orders** - Crea Ã³rdenes de trabajo vÃ­a Backend API
3. **publish_notifications** - Publica notificaciones para tÃ©cnicos
4. **send_summary_email** - EnvÃ­a resumen por email

**CaracterÃ­sticas:**
- âœ… Consulta directa a Cloud SQL
- âœ… CreaciÃ³n automÃ¡tica de Ã³rdenes de trabajo
- âœ… Notificaciones a tÃ©cnicos
- âœ… Resumen diario por email
- âœ… Manejo de errores robusto

**LÃ³gica de Negocio:**
```sql
SELECT * FROM maintenance_maintenanceplan
WHERE is_active = true
AND next_due_date <= CURRENT_DATE
AND asset.status = 'ACTIVE'
```

### 3. Report Generation DAG (`weekly_kpi_report`)

**PropÃ³sito:** Genera y envÃ­a reportes semanales de KPIs.

**Schedule:** Semanal (Lunes a las 8 AM)

**Tareas:**
1. **extract_kpi_data** - Extrae datos de KPIs de la BD
2. **generate_charts** - Genera grÃ¡ficos con matplotlib
3. **generate_pdf_report** - Genera reporte HTML/PDF
4. **upload_report_to_gcs** - Sube reporte a Cloud Storage
5. **send_report_email** - EnvÃ­a reporte por email con SendGrid

**KPIs Incluidos:**
- ğŸ“Š Ã“rdenes de trabajo (total, completadas, en progreso, pendientes)
- â±ï¸ MTTR (Mean Time To Repair)
- ğŸ”§ MTBF (Mean Time Between Failures) por tipo de vehÃ­culo
- ğŸ“¦ Inventario (total, stock bajo, valor)
- ğŸ”® Predicciones ML (alto riesgo, crÃ­tico, probabilidad promedio)

**GrÃ¡ficos:**
- DistribuciÃ³n de Ã³rdenes de trabajo por estado
- MTBF por tipo de vehÃ­culo

## ğŸ”§ Scripts de Soporte

### Feature Engineering Script (`feature_engineering.py`)

**PropÃ³sito:** Procesa datos crudos y crea caracterÃ­sticas para ML.

**CaracterÃ­sticas Generadas:**
- `asset_age_days` - Edad del activo en dÃ­as
- `days_since_last_maintenance` - DÃ­as desde Ãºltimo mantenimiento
- `total_work_orders` - Total de Ã³rdenes de trabajo
- `completed_work_orders` - Ã“rdenes completadas
- `high_priority_work_orders` - Ã“rdenes de alta prioridad
- `critical_work_orders` - Ã“rdenes crÃ­ticas
- `avg_repair_hours` - Horas promedio de reparaciÃ³n
- `work_order_completion_rate` - Tasa de completitud
- `high_priority_ratio` - Ratio de prioridad alta

**TecnologÃ­a:** PySpark en Dataproc

## ğŸ”Œ Backend Integration

### Composer Client (`composer_client.py`)

Cliente Python para interactuar con Airflow API:

```python
class ComposerClient:
    def trigger_dag(dag_id, conf)
    def get_dag_status(dag_id)
    def get_dag_runs(dag_id, limit)
    def list_dags()
```

**ConfiguraciÃ³n:**
```python
AIRFLOW_WEBSERVER_URL = os.getenv('AIRFLOW_WEBSERVER_URL')
AIRFLOW_USERNAME = os.getenv('AIRFLOW_USERNAME')
AIRFLOW_PASSWORD = os.getenv('AIRFLOW_PASSWORD')
```

### API Endpoints

**Base URL:** `/api/v1/core/composer/`

**Endpoints:**
```
GET  /list_dags/                      - Lista todos los DAGs
POST /trigger_etl_ml_training/        - Inicia ETL y ML training
POST /trigger_preventive_maintenance/ - Inicia generaciÃ³n de mantenimiento
POST /trigger_report_generation/      - Inicia generaciÃ³n de reportes
GET  /dag_status/?dag_id=<id>         - Estado de un DAG
GET  /dag_runs/?dag_id=<id>&limit=10  - Ejecuciones recientes
```

**AutenticaciÃ³n:** Bearer Token (Admin only)

**Ejemplo de Uso:**
```bash
curl -X POST \
  http://localhost:8000/api/v1/core/composer/trigger_etl_ml_training/ \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{"conf": {}}'
```

## ğŸ¨ Frontend - Admin UI

### Admin Page (`Admin.tsx`)

**Ruta:** `/admin`

**CaracterÃ­sticas:**
- ğŸ›ï¸ Botones para iniciar cada DAG manualmente
- ğŸ“‹ Lista de DAGs disponibles con estado
- âœ… Feedback visual de Ã©xito/error
- ğŸ”„ Estados de carga

**Componentes:**
- Tarjetas para cada DAG con descripciÃ³n
- Botones de trigger con estados de carga
- Mensajes de Ã©xito/error
- Tabla de DAGs disponibles

## ğŸ“ Estructura de Archivos

```
proyecto/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ etl_ml_training_dag.py
â”‚   â”‚   â”œâ”€â”€ preventive_maintenance_dag.py
â”‚   â”‚   â””â”€â”€ report_generation_dag.py
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ feature_engineering.py
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ apps/
â”‚       â””â”€â”€ core/
â”‚           â”œâ”€â”€ composer_client.py
â”‚           â”œâ”€â”€ views.py
â”‚           â””â”€â”€ urls.py
â””â”€â”€ frontend/
    â””â”€â”€ src/
        â””â”€â”€ pages/
            â””â”€â”€ Admin.tsx
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Airflow

```python
# GCP Configuration
gcp_project_id = "your-project-id"
gcp_region = "us-central1"
gcs_bucket_name = "cmms-ml-data"

# Backend API
backend_api_url = "http://backend-service-url"
backend_api_token = "your-api-token"

# Email Configuration
alert_email = "admin@cmms.com,team@cmms.com"
report_email = "reports@cmms.com"
sendgrid_api_key = "your-sendgrid-key"
```

### Conexiones de Airflow

```python
# Cloud SQL PostgreSQL
cloudsql_postgres:
  conn_type: postgres
  host: /cloudsql/project:region:instance
  schema: cmms_db
  login: postgres
  password: <password>
```

### Variables de Entorno (Backend)

```bash
# Airflow Configuration
AIRFLOW_WEBSERVER_URL=https://your-composer-url
AIRFLOW_USERNAME=admin
AIRFLOW_PASSWORD=<password>
```

## ğŸš€ Despliegue

### 1. Crear Composer Environment

```bash
gcloud composer environments create cmms-composer \
  --location us-central1 \
  --python-version 3 \
  --machine-type n1-standard-4
```

### 2. Subir DAGs

```bash
gcloud composer environments storage dags import \
  --environment cmms-composer \
  --location us-central1 \
  --source airflow/dags/
```

### 3. Subir Scripts

```bash
gsutil cp airflow/scripts/feature_engineering.py \
  gs://cmms-ml-data/scripts/
```

### 4. Configurar Variables

```bash
gcloud composer environments run cmms-composer \
  --location us-central1 \
  variables set -- \
  gcp_project_id your-project-id
```

### 5. Configurar Conexiones

```bash
gcloud composer environments run cmms-composer \
  --location us-central1 \
  connections add cloudsql_postgres \
  --conn-type postgres \
  --conn-host /cloudsql/project:region:instance \
  --conn-schema cmms_db \
  --conn-login postgres \
  --conn-password <password>
```

## ğŸ“Š Monitoreo

### Airflow UI

Acceder a: `https://your-composer-url/home`

**Vistas Disponibles:**
- DAGs - Lista de todos los DAGs
- Graph View - VisualizaciÃ³n de tareas
- Tree View - Historial de ejecuciones
- Logs - Logs detallados de cada tarea

### Cloud Logging

```bash
# Ver logs de DAG runs
gcloud logging read "resource.type=cloud_composer_environment" \
  --limit 50 \
  --format json
```

### MÃ©tricas

- DuraciÃ³n de ejecuciÃ³n de DAGs
- Tasa de Ã©xito/fallo
- Uso de recursos de Dataproc
- Costos de ejecuciÃ³n

## ğŸ” Troubleshooting

### DAG no se ejecuta

1. Verificar que el DAG no estÃ© pausado
2. Revisar schedule_interval
3. Verificar start_date y catchup

### Error en extracciÃ³n de datos

1. Verificar conexiÃ³n a Cloud SQL
2. Revisar permisos de la cuenta de servicio
3. Verificar queries SQL

### Error en Dataproc

1. Verificar quotas de GCP
2. Revisar configuraciÃ³n del cluster
3. Verificar script de PySpark en GCS

### Error en Backend API

1. Verificar token de autenticaciÃ³n
2. Revisar URL del backend
3. Verificar logs del backend

## âœ… Testing

### Test Manual de DAGs

```python
# En Airflow UI
1. Ir a DAGs
2. Click en el DAG
3. Click en "Trigger DAG"
4. Monitorear ejecuciÃ³n en Graph View
```

### Test de Endpoints

```bash
# Listar DAGs
curl -X GET \
  http://localhost:8000/api/v1/core/composer/list_dags/ \
  -H "Authorization: Bearer <token>"

# Trigger DAG
curl -X POST \
  http://localhost:8000/api/v1/core/composer/trigger_etl_ml_training/ \
  -H "Authorization: Bearer <token>"
```

## ğŸ“ˆ Mejoras Futuras

1. **Alertas Avanzadas:**
   - IntegraciÃ³n con PagerDuty
   - Alertas a Slack/Teams
   - Umbrales personalizables

2. **Optimizaciones:**
   - Cache de datos intermedios
   - ParalelizaciÃ³n de tareas
   - Uso de Dataflow en lugar de Dataproc

3. **Reportes:**
   - Dashboards interactivos
   - Reportes personalizables
   - ExportaciÃ³n a mÃºltiples formatos

4. **ML Pipeline:**
   - A/B testing de modelos
   - Monitoreo de drift
   - Reentrenamiento automÃ¡tico

## ğŸ‰ ConclusiÃ³n

La implementaciÃ³n de Cloud Composer estÃ¡ completa con:
- âœ… 3 DAGs principales funcionando
- âœ… Script de PySpark para feature engineering
- âœ… Cliente de Composer en Backend
- âœ… API endpoints para triggers manuales
- âœ… UI de administraciÃ³n en Frontend
- âœ… Notificaciones por email
- âœ… IntegraciÃ³n completa con Backend
- âœ… DocumentaciÃ³n completa

El sistema de automatizaciÃ³n estÃ¡ listo para producciÃ³n y puede ser desplegado en GCP Cloud Composer.
